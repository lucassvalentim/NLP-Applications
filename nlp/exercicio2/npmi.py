# üìä ETAPA 1: 
# Entendendo o NPMI (Normalized Pointwise Mutual Information):
'''
O objetivo do NPMI √© dizer se as palavras que constroem um t√≥pico de fato o representa. Isto √©, se as palavras presentes
no t√≥pico representam de fato o tema do mesmo. Para isso, o NMPI √© usado para medir o quanto as palavras de um t√≥pico tendem 
a aparecer juntas nos mesmos documentos.Se as palavras de um t√≥pico aparecem frequentemente juntas, o NMPI ser√° mais alto, 
indicando que o t√≥pico √© mais coeso.

Resumindo: Ele mede o qu√£o bem as palavras dentro de um t√≥pico est√£o semanticamente relacionadas, 
ajudando a verificar se um t√≥pico faz sentido.
'''

# üìã ETAPA 2: Passo a passo pr√°tico para calcular o NPMI

# Passo 1: Importar bibliotecas necess√°rias
import numpy as np
from collections import Counter
from itertools import combinations

# Passo 2: Definir uma fun√ß√£o que calcula as coocorr√™ncias das palavras em documentos

def get_word_cooccurrences(docs, topic_words):
    """
    Calcula as coocorr√™ncias de palavras em uma lista de documentos.
    
    Par√¢metros:
    - docs: Lista de documentos (listas de palavras j√° pr√©-processadas)
    - topic_words: Lista de palavras do t√≥pico a ser analisado
    
    Retorna:
    - cooc_counts: Contagem de coocorr√™ncias das palavras do t√≥pico
    - word_counts: Contagem de apari√ß√µes individuais de cada palavra
    """
    cooc_counts = Counter()
    word_counts = Counter()

    for doc in docs:
        # Filtrar palavras que pertencem ao t√≥pico
        filtered_words = [word for word in doc if word in topic_words]
        
        # Atualizar contagem de palavras individuais
        word_counts.update(filtered_words)
        
        # Atualizar contagem de coocorr√™ncias
        for pair in combinations(filtered_words, 2):
            cooc_counts[tuple(sorted(pair))] += 1

    return cooc_counts, word_counts

# Passo 3: Definir uma fun√ß√£o que calcula o PMI

def calculate_pmi(cooc_counts, word_counts, total_docs):
    """
    Calcula o PMI (Pointwise Mutual Information) entre pares de palavras.
    
    Par√¢metros:
    - cooc_counts: Contagem de coocorr√™ncias das palavras do t√≥pico
    - word_counts: Contagem de apari√ß√µes individuais de cada palavra
    - total_docs: N√∫mero total de documentos
    
    Retorna:
    - pmi_scores: Dicion√°rio com os pares de palavras e seus respectivos PMIs
    """
    pmi_scores = {}

    for (w1, w2), cooc in cooc_counts.items():
        p_w1 = word_counts[w1] / total_docs
        p_w2 = word_counts[w2] / total_docs
        p_w1_w2 = cooc / total_docs

        # Calcular PMI
        pmi = np.log(p_w1_w2 / (p_w1 * p_w2))
        pmi_scores[(w1, w2)] = pmi

    return pmi_scores

# Passo 4: Normalizar o PMI para obter o NMPI

def normalize_pmi(pmi_scores):
    """
    Normaliza os valores de PMI para obter o NMPI.
    
    Par√¢metros:
    - pmi_scores: Dicion√°rio com os pares de palavras e seus respectivos PMIs
    
    Retorna:
    - nmpi_scores: Dicion√°rio com os pares de palavras e seus respectivos NMPIs
    """
    max_pmi = max(pmi_scores.values())
    min_pmi = min(pmi_scores.values())

    nmpi_scores = {pair: (pmi - min_pmi) / (max_pmi - min_pmi) for pair, pmi in pmi_scores.items()}
    
    return nmpi_scores

# üìä ETAPA 3: Aplicar a avalia√ß√£o de NMPI em t√≥picos gerados

# Suponha que temos os seguintes documentos pr√©-processados e um t√≥pico gerado
docs = [
    ["data", "science", "machine", "learning"],
    ["machine", "learning", "model"],
    ["data", "model", "prediction"],
    ["science", "data", "learning"]
]

topic_words = ["data", "science", "machine", "learning"]

# Calcular coocorr√™ncias
cooc_counts, word_counts = get_word_cooccurrences(docs, topic_words)

# Calcular PMI
total_docs = len(docs)
pmi_scores = calculate_pmi(cooc_counts, word_counts, total_docs)

# Calcular NMPI
nmpi_scores = normalize_pmi(pmi_scores)

# Exibir resultados
print("\nCoocorr√™ncias das palavras do t√≥pico:")
print(cooc_counts)

print("\nPMI Scores:")
print(pmi_scores)

print("\nNMPI Scores:")
print(nmpi_scores)
